\chapter{Reconstruction and identification of physical objects}
\label{ch:objects}
\epigraph{\emph{“Champions keep playing until they get it right.”}}{Billie Jean King}


The particles (and products of their decays) produced at every collission, interact with the detector in a particular manner according to their nature. The information recollected by all the sub-detectors described in the previous chapter allow for the reconstruction and identification of the physical objects present in each accepted event by the trigger system. Two types of reconstruction and identification exist. The \textit{online} one, is carried out at the same time the \pp collissions take place, and the \textit{offline} one, done after the events are saved to storage. The reconstruction is done event by event, and is carried in the same way for events recorded by the \ac{ATLAS} detector and for simulated \ac{MC} events. In the following, a brief overview of the offline reconstruction and identification of the objects used in this thesis is given.







\section{Track and vertex reconstrucion}

In a high-pileup event, there can be of the order of 1000 charged particles passing through the \ac{ATLAS} detector. The information from the \ac{ID} (\Sect{\ref{subsec:atlas:atlas:id}}) is used to reconstruct the trajectories of charged particles, called \textit{tracks}.

Tracking charged particles is a critical step in reconstruction. Tracks encode charged particles' momentum and trajectory, playing an essential role in particle identification and primary vertex reconstruction. As the inner detector is closest to the beamline and comprises minimally ionizing detector material with high granularity, it plays the main role in track reconstruction. A charged particle passing through different layers of \ac{ID} leaves a signal via ionization. As the \ac{ID} solenoidal field is homogenous, the resulting trajectory is circular in the \(xy\) plane. Five parameters shown in FIGURE define charged particle tracks:
\begin{itemize}
    \item \(q/\pt\): the ratio of the charge and transverse momentum defining the curvature
    \item \(d_0\): the distance of the closest approach to the primary vertex in \(xy\)-plane defining the transverse impact parameter
    \item \(z_0\): the longitudinal impact parameter along the \(z\)-axis
    \item \(\phi_0\): the azimuthal angle
    \item \(\theta_0\): the polar angle of the particle direction oat the closest point of approach~\cite{PerformanceTracksRun2}.
\end{itemize}


The track reconstrucion used in Run-2 uses two complementary approaches: the \textit{inside-out} approach, and the \textit{outside-in}~\cite{ATLASNEWT}. 

The first step in the inside-out track reconstruction is the seed-finding, where three hits in the silicon detector are searched for to seed the track reconstruction. Using these three hits and assuming an uniform magnetic field, a first estimate of the track parameters is obtained. Using the track seeds, the track is extrapolated to the other silicon layers, from which a combinatorial Kalman filter is used to estimate the track parameters. At this stage of the process there can be several track candidates for each track seed. Once the track is formed, an ambiguity resolution algorithm is applied to reassign shared clusters to the track with a better match~\cite{ATLASNNClustering}, and the final track candidate is fitted using a global \chisq method. The last part of the inside-out method consists on extending the tracks to the \ac{TRT}, and including the \ac{TRT} hits to the track, to improve the track's momentum resolution.

To improve the eciency for tracks from decays displaced from the original collision point, an outside-in track reconstruction algorithm is also used. The track is seeded with hits from the \ac{TRT}. The track is extended to include hits from the silicon detector, with an ambiguity solver again applied to mitigate the hit sharing between two tracks.

Primary and secondary vertices are of vital importance for the subsequent object reconstruction in \ac{ATLAS}. In this step, the tracks found as explained previously are used as input to the vertexing algorithm~\cite{ATLASPVReconstruction,ATLASVertexReconstruction}. First of all, the \ac{PV} is defined as the location where two protons collide. \acp{PV} are reconstructed by matching up intersecting tracks, which proceeds in three main steps: seeding, track assignment, and fitting. The vertex with the largest \(\sum \pt^2\) for all associated tracks is labeled as the hard-scatter vertex. There are some particles that decay rapidly after their production, such as \(\tau\) leptons or heavier quarks (\(b\) or \(\cquarks\)), and their decay position can be measured. From the remaining tracks originated from these decays, it is possible to identify secondary vertices. All the remaining reconstructed vertices are considered to be pile-up.








\section{Photons and electrons}

The reconstruction of electrons and photons in \ac{ATLAS} is based on the energy deposition in the \ac{ECAL}. Since electrons and photons leave similar signals in the \ac{ECAL}, their reconstrucion is done simultaneously, distinguishing between them by the reconstructed track information left in the \ac{ID}.


\subsection{Reconstruction}

The \textit{offline} photon and electron reconstruction~\cite{ATLASEGammaPerformance20152017,ATLASTopoClustersRun2} makes use of dynamic, variable-size clusters, connected topologically between the \ac{ECAL} and \ac{HCAL} cells~\cite{ATLASTopoClustersRun1}, called topo-clusters. This approach allows for the clusters to recover energy from bremsstrahlung photons or from electrons from photon conversions.

There are three types of objects:
\begin{itemize}
    \item Electrons: consists of a cluster built from the energy deposits in the \ac{ECAL} and a matched track.
    \item Converted photons: consits of a cluster mathed to a conversion vertex (or vertices)
    \item Unconverted photons: cluster matched to neither an electron track nor a conversion vertex.
\end{itemize}
The algorithm for the reconstruction of electrons and photons proceeds as shown in FIGURE.

The reconstruction process begins with the topo-cluster formation. First, proto-clusters are formed in the \ac{ECAL} and \ac{HCAL} by grouping cells that have a required energy, and by subsequently adding neighbouring cells in four consecutive steps, obtaining the topo-cluster. Reconstructions starts only in those cases where the topo-clusters energy in the \ac{ECAL} is greater than \(400~\mev\).

The algorithm also builds conversion vertices out of the refitted tracks and matches them to the selected topo-clusters.
After the initial track-cluster matching and conversion building, the electron and photon supercluster algorithms run separately in parallel. In the first stage, topo-clusters are evaluated for use as seed cluster candidates, which form the basis of superclusters; in the second stage, clusters near the seed candidates are identified as satellite cluster candidates, which may emerge from bremsstrahlung radiation or topo-cluster splitting. Satellite clusters are added to the seed candidates to form the final superclusters, if they pass the necessary selection criteria
After applying initial position corrections to the resultant superclusters, the reconstruction algorithm matches tracks to
the electron superclusters and conversion vertices to the photon superclusters.

Since one object may be reconstructed as both an electron and a photon, an ambiguity resolution is performed to remove part of the overlap. However, some overlap is allowed in order to maintain a high reconstruction efficiency for electrons and photons, to which physics analyses may apply their own criteria. The final electrons and photons are then built and calibrated, facilitating the calculation of additional variables used for quality cuts and ambiguity resolution



\subsection{Identification}

In order to distinguish real photons (those coming from the collision) from background photons which have much larger production cross sections (coming from hadrons decays, also called fake photons), it is necessary to rely on a algorithm of identification with high signal efficiency and background rejection, for photon candidates with \(\pt \sim 10~\gev\) up to the \tev scale. 
Currently, photon identification in ATLAS is based on a set of rectangular cuts on \acp{SSV} computed from the energy deposited in the cells of the cluster in the first and second layer of the \ac{ECAL}, and from the leakage to the \ac{HCAL}. These variables describe the passage of the photons through the calorimeters, characterizing the lateral and longitudinal electromagnetic showers.
In general, real photons produce narrower energy deposits in the \ac{ECAL}, and have lower leakages to the \ac{HCAL}, compared to those photons proveninent from hadrons. The reason behind this behaviour is the presence of additional neighbouring hadrons close to the fake photon.
Furthermore, since the first layer of the \ac{ECAL} consists on fine strips, it is possible to discriminate photon candidates coming from \(\pizero\to\gamma\gamma\) decays, characterized by two local maxima due to the presence of two nearby photons.

In the following, the \acp{SSV} used for photon identification are detailed.
The first variable makes use of the energy measured in the \ac{HCAL}:
\begin{itemize}
    \item Hadronic leakage: is the trasnverse energy deposited in the \ac{HCAL}, normalized to the energy deposited in the \ac{ECAL}:
        \begin{equation}
            {\rhad}_{(1)} = \frac{\et^{\text{had}}}{\et^{\text{EM}}}
        \end{equation}
        In order to minimize the effects of resolution degradation, in the barrel-endcap transition region of the \ac{HCAL} (\(0.8\leq \abseta\leq 1.37\)) the energy deposit in the whole \ac{HCAL} is used (\rhad). On the reminaing of the detector, only the energy deposited in first layer of the \ac{HCAL} is used (\rhado).
\end{itemize}
The following variables use the second-layer information of the \ac{ECAL}:
\begin{itemize}
    \item Lateral energy profile in \(\eta\):
        \begin{equation}
            \reta = \frac{E_{3\times7}^{s2}}{E_{7\times7}^{s2}}
        \end{equation}
        where \(E_{i\times j}^{s2}\) is the energy sum in the second calorimeter layer contained in a window of \(i \times j \) cells (units of \(\eta \times \phi\) cells), centered at the most energetic cell. This variable gives a measure of the showers' width in the \(\eta\) direction.
    \item Lateral energy profile in \(\phi\):
        \begin{equation}
            \rphi = \frac{E_{3\times3}^{s2}}{E_{3\times7}^{s2}}
        \end{equation}
        defined in a similar way as \reta. However, this variable behaves very different for converted and unconverted photons. Due to the action of the magnetic field, the electrons and positros are curved into opposite directions in \(\phi\), having as a result, \ac{EM} showers much wider in the case of converted photons than those for unconverted ones.
    \item Lateral shower width in \(\eta\):
        \begin{equation}
            \weta = \sqrt{
                \frac{\sum E_i \eta_i^2}{\sum E_i}
                -
                \left(\frac{\sum E_i \eta_i}{\sum E_i}\right)^2
            }
        \end{equation}
        measures the proper width of the \ac{EM} shower, where \(E_i\) is the energy in the \(i\)-th cell of the \ac{ECAL}, measured in a window of \(3\times 5 \) cells in \(\eta \times \phi\).
\end{itemize}






































































%  \section{Object Reconstruction}
%  \label{sec:DAQ:ObjectReco}
% After the selection of events through the signature triggers described above,  the particle signatures are reconstructed and identified \textit{offline},  after they have been saved to storage.  This reconstruction is done event by event with the same procedure applied to Monte Carlo simulation and recorded ATLAS data. 
% Each particle has its reconstruction and identification procedure and can have additional algorithms to help with the specification of its properties.  Since the event is already recorded,  less limitations on the CPU consumption and timing constraints governing the online reconstruction can be used. 
% In the following,  a brief overview of the offline reconstruction and identification of the objects used in this thesis is given. 

% \subsection{Electrons}
%   \label{sec:DAQ:ObjectReco:Electrons}
 
% The main features of an electron or positron (in the following both referred to as electron) in ATLAS is a cluster of energy deposits in the \ac{ECAL},  tracks in the \ac{ID}  as well as a close match between the clusters and tracks in terms of $\eta \times \phi$.
% These three main features present the three consecutive steps in reconstructing electrons: first,  a seed cluster is reconstructed: Based on a sliding-window algorithm,  looking at collections of energy towers with at least 2.5 GeV of summed transverse energy. 
% Here an energy tower is the sum of collected energy in all three layers of the \ac{ECAL},  including the presampler,  in a $\Delta \eta \times \Delta \phi = 0.025 \times 0.025$ segment. This mimics the granularity of the second layer of the \ac{ECAL}.
% In Figure \ref{fig:DAQ:egammareco},  the path of an electron through the different detector components is illustrated,  also highlighting the three different layers in the \ac{ECAL}.

% \begin{figure}
% \centering
% \includegraphics[width=0.8\linewidth]{figures/DAQ/EgammaReco.png}
% \caption{Illustration of an electron path through the Inner Detector and Calorimeters of ATLAS,  highlighting the layer granularity in the electromagnetic calorimeter.  The dashed line presents a photon produced through interactions of the electron with the \ac{ID} material. Taken from \cite{ElectronRecoID1516}. \label{fig:DAQ:egammareco}}
% \end{figure}

% After the seed cluster is identified,  tracks are reconstructed.  This is based on pattern recognition of hits in the \ac{SCT} and Pixels,  followed by an ambiguity resolution step,  resolving ambiguity of hits associated with multiple tracks, and an extension of the tracks to the \ac{TRT}.
% For the fitting of tracks,  a global $\chi^2$ fitting procedure is used,  with either a pion hypothesis or an electron hypothesis in the presence of significant Bremsstrahlung. 
% Consecutively,  a \ac{GSF} \cite{GSF} is applied to account for energy losses in the \ac{ID} material. 
% As the last electron reconstruction step,  a matching of the GSF-track and calorimeter cluster is performed.  This matching is based on a geometric distance between the clusters and tracks and is described in detail in \cite{ElectronRecoID1516}.  The electromagnetic energy clusters are further calibrated as described in \cite{ElectronCalib}.

% After the reconstruction,  a further identification is necessary to distinguish prompt electrons from electrons originating from misidentified hadrons, non-isolated electrons from heavy-flavour decays or electrons from photon conversion. 

% This identification is based on a likelihood discriminant construction.  The likelihood discriminant $d'_L$ is given in equation\eqref{eqn:daq:eleclikelihood} \cite{ElectronRecoID1516},  where a fixed factor $\tau = 15$ is used to achieve a smooth discriminant distribution.   

% \begin{align}
% \begin{split}
% d_L &= \frac{L_S}{L_S + L_B} \\
% d'_L &= -\tau^{-1} \ln(d^{-1}_L -1)
% \label{eqn:daq:eleclikelihood}
% \end{split}
% \end{align}

% Here $L_S$ describes the likelihood function of signal,  prompt electrons. Whereas $L_B$ is the likelihood of non-promt,  fake electrons.  The likelihoods $L_S$ and $L_B$ are a product of probability density functions for a large set of kinematic variables.  The distributions and the likelihoods are binned in the $p_T$ and $\eta$ of the electron candidate.  A complete set of the variables considered in the likelihood definition is included in \cite{ElectronRecoID1516}, as well as a detailed description of the pdf and likelihood extraction.  
% Using a multi-variate technique can help where a simple cut on single variables would not offer strong discriminating power.  
% %based on discussion and drafting with Stefan Richter! 
% Based on the output of the discriminant,  several working points are defined.  These are designed to have a given signal-electron selection efficiency in each $(p_T, \eta)$ bin. Therefore a cut on the discriminant is defined in each $(p_T, \eta)$ bin.  In addition, to stabilise the performance at high pileup (to avoid getting too much increase in background passing the selection),  the cut on the discriminant is done such that it depends linearly on a pileup variable.  
% %in each $p_T-\eta$ bin i
% Effectively,  the cut gets tightened as pileup increases.  The number of primary vertices in the event is used as the pileup variable for offline electrons.  For online electrons, this is too computationally intense, so the number of inelastic collisions per bunch crossing ($\mu$) is used instead as a measure of the amount of pileup.
% Additional to the electron likelihood based identification,  isolation requirements can be applied to distinguish between prompt electrons and electrons from heavy-flavour decays.  Two isolation criteria for offline electrons are defined,  \textit{FCTight} and \textit{FCLoose}.  These isolation working points include a restriction on the transverse energy sum in a $\Delta R <0.2$ region around the electron in the calorimeter ($E_T^\text{iso}$) to be below 0.06 and 0.2 times the electrons energy ($E_T$), for \textit{FCTight} and \textit{FCLoose}, respectively.  The calorimeter based isolation requirement is combined with a track-based isolation, restricting the momentum.  The radial distance has a maximum value of 0.2 and decreases with the electrons momentum.  For the \textit{FCTight} working point,  the momentum fraction within the isolation cone is restricted to be smaller than  0.06 times the electrons momentum,  for \textit{FCLoose} it is below 15\% of the electrons momentum. 
% %pileup distr in each pt eta bin - schnitt auf disk linear function of pileup dependency
% %id menu dep pt eta and pileup 
% %disc schnitt (Y) pileup (X) - steigung konstruiert 0 very loose , tight am stärksten - damit tight immer medium erfüllt und es nicht vorkommen kann dass tight für hohes pileup medium nicht erfüllt

  
%   \subsection{Muons}
% Muon candidates as minimum ionising particles in ATLAS are reconstructed using track segments from the Muon Spectrometer that have been matched to \ac{ID} tracks.  Energy loss in the calorimeters is taken into account in a combined fitting of \ac{MS} and \ac{ID} tracks.  
% Multiple identification working points in varying levels of prompt muon selection efficiency and background rejection are defined,  designed to satisfy the large varying needs of physics analyses.  Additional to identification criteria,  an isolation requirement can be applied \cite{MuonID}.  Similar to the electron isolation working points,  a muon isolation based on calorimeter and track-based isolation criteria is defined,  \textit{FCLoose}.  The transverse energy in a  $\Delta R < 0.2$ isolation cone around the muon is restricted to 30\% of the muons momentum.  Addtionally, the momentum in a variable size, maximum $\Delta R < 0.3$ cone around the muon should not extend 15\% of its momentum. 

% \subsection{Jets}
% The particle-flow jet reconstruction \cite{ParticleFlow} makes use of calibrated Topoclusters as well as tracking information from the \ac{ID}.  The topological clustering algorithm has been previously introduced and discussed in section \ref{sec:daq:tautriggers} in relation to tau triggers. The anti-$k_T$ sequential recombination algorithm \cite{antikt} is used to form jet objects based on particle-flow objects.  To remove pile-up jets,  a multivariate discriminant based on vertex information,  the \ac{JVT} \cite{JVT} can be used.

% %topological clusters of calorimeter cells 

% \subsection{Taus}
% \label{sec:DAQ:ObjectReco:Taus}
% As briefly highlighted within the description of the tau trigger in section \ref{sec:daq:tautriggers},  hadronic tau decays have a distinct detector signature that can be used to trigger on events containing hadronic taus.  In the following,  a brief discussion of the tau decay is given to provide a baseline of the features important to this thesis, before summarizing the hadronic tau reconstruction and identification within \ac{ATLAS}.
% Tau leptons have a mass of $1776.86  \text{ MeV}$ and a mean lifetime of $290.3 \times 10^{-15} \text{ s}$ \cite{PDG2022}. With their proper decay length around $87 \mu\text{m}$ \cite{PDG2022},  taus decay before interacting with active detector layers of \ac{ATLAS}.  As can be seen in Figure \ref{leptaudecay},  tau leptons decay via a $W$ boson and a tau neutrino.  The hadronic or leptonic decay of the tau is determined through the consecutive decay of the $W$-boson,  Figure \ref{leptaudecay}, highlighing a leptonic decay into an electron. Leptonic decays of the tau make up 35\% of tau decays, with hadronic decays making up 65\% \cite{PDG2022}.  Examples of hadronic tau decays are given in Figure \ref{hadtaudecay},  highlighting the calorimeter systems in which the decay products will leave the majority of their energy.  Not explicitely shown in the sketch is the $W$-boson,  only its decay products.  In 72\% the hadronic tau decay includes one charged pion,  in 22\% of the cases the decay includes three charged pions.  These charged pions leave tracks in the \ac{ID},  presenting a distinct identfication feature of taus,  the number of charged tracks or \textit{prongs} associated with their decay. 
% %t 65% of all possible decay modes [1]. In these, the hadronic decay products are one or three charged pions in 72% and 22% of
% %all cases, respectively. 
% The hadronic decay of a tau lepton is determined through the quarks and intermediate mesons built in the $W$-boson decay.  Examples thereof are shown in Figure \ref{hadtaudecay}. 
% \begin{figure}[h]
% \subfloat[\label{leptaudecay}]{\includegraphics[width=0.25\linewidth]{figures/tauLep.pdf}}
% \subfloat[\label{hadtaudecay}]{\includegraphics[width=0.7\linewidth]{figures/taudecay.pdf}}
% \caption{Feynman diagram of a leptonic tau decay,  highlighting its decay via a W-boson (a). Examples of hadronic tau decays into (from left to right) one charged pion,  one charged and one neutral pion as well as three charged pion (b)\cite{TauDecayTikz},  highlighting in which detector systems the participating particles will be detected.  \label{taudecay}}
% \end{figure}

% Hadronic tau candidates are seeded from jets that have been reconstructed using the anti-$k_T$ algorithm,  with a distance parameter of $\Delta R =0.4$  \cite{TauReconstruction}.  Additionally,  jet seeds are required to have $p_T > 10 \text{ GeV}$ and $|\eta| <2.5$.
% %A tau vertex is identified among all primary vertex candidates that lies within $\Delta R < 0.2$ of the jet axis.
% A \ac{BDT} is used to categorize all tracks associated to the tau candidate within $\Delta R = 0.4$ of the tau axis to be core or isolation tracks.  The number of core tracks is used to define the prongness of taus,  indicating the number of charged particles involved in the tau's decay.

% To distinguish tau particles from jets,  a recurrent neural network (RNN) identification is used.   
% For this,  multiple kinematic variables are used for the training of an RNN \cite{TauRNNID}.    
% Variables include specifications of the cluster depth, the longitudinal extension and the radial cluster extension as well as fractions of momenta in the core or isolation region of the tau cluster,  to highlight a few of them. 
% The performance of the RNN identifier is shown in Fig. \ref{fig:DAQ:tauPerformance} for its 1-prong and 3-prong decay modes. This is also compared with the performance of a BDT identifier previously used in the $\tau$ identification in ATLAS.  The improved network architecture of the RNN identifier provides  rejection of jets by up to a factor of two better than the previous BDT approach. 

% \begin{figure}[h]
% \centering
% \includegraphics[width=0.6\linewidth]{figures/DAQ/RNNPerformance.png}
% \caption{Performance of the tau \ac{RNN} identification working points in comparison with previously used \ac{BDT} based identification \label{fig:DAQ:tauPerformance} \cite{TauRNNID}}
% \end{figure}

% \subsection{Missing transverse energy}
% The reconstruction of missing transverse energy after an event has been stored by a trigger is similar to the procedure at trigger level described in section \ref{sec:DAQ:SignatureTriggers}.  In contrast to the trigger reconstruction,  the offline missing transverse energy reconstruction is not based on uncalibrated clusters, but fully calibrated physics objects.  Additionally to this part of the \Met reconstruction considering physics object,  a soft term comprised of low momentum tracks is taken into account \cite{MetPerformance}.

% \section{Monte Carlo Simulation}
% \label{sec:DAQ:MC}
% To evaluate any measurements taken with the ATLAS detector,  simulations of physics processes and their decay within the ATLAS detector are necessary.  This is achieved through the use of Monte Carlo event generators.  In the following,  a brief description of the essentials of Monte Carlo simulations are given,  based on pedagogic introductions given in \cite{MCPedagogic}.  Followed by a short overview of the Monte Carlo generators used in this thesis.
% For the production of a final state X through the collision of two hadrons ($h_1$, $h_2$),  the inclusive cross section can be factorised like the following:

% \begin{align}
% \sigma_{h_1,h_2\rightarrow X} = \sum_{a,b\in {q,g}} \int dx_a \int dx_b f_a^{h_1}(x_a,\mu_F^2)f_b^{h_2}(x_b, \mu_F^2) \int \,d\Phi_{ab\rightarrow X} \frac{d\hat{\sigma}_{ab}(\Phi_{ab\rightarrow X},\mu_F^2)}{\,d\Phi_{ab\rightarrow X} }
% \label{eq:DAQ:xsec}
% \end{align}
% With $f_a^{h_1}(x_a,\mu_F^2)f_b^{h_2}(x_b, \mu_F^2)$ representing the parton distribution functions. 
% Here $\mu_F$ presents the factorisation scale.  This scale is the cutoff between processes that are considered perturbatively and the non-perturbative regime.  
% %In order to evaluate the systematic uncertainty caused by the cross section's dependence on the factorisation scale,  this scale is varied in alternative samples.
% An important part of this inclusive cross section is presented by the Matrix element describing the hard scattering process,  this is included in the last integral of equation \eqref{eq:DAQ:xsec}.
% After the inclusive matrix element calculation as described in equation \eqref{eq:DAQ:xsec},  the parton showering takes into account the additional particles that can contribute to the production.  The parton showering here is considering that a parton can originate from a splitting of  other partons.
% To not consider the additional particles twice,  a matching of the matrix element and the parton showering has to be performed.  
% The produced partons in such a showering will form colourless hadrons,  which in turn can further decay.  A last aspect to be taken into consideration for event simulations is the underlying event. This is caused by \textit{spectator} partons, not directly participating in the hard scattering.


% \subsection{Monte Carlo generators}

% \paragraph{Sherpa}
% One of the general purpose event generators used in this thesis is \texttt{SHERPA} \cite{Sherpa}.  It includes matrix element generators as well as a built-in parton showering.  In this thesis,  simulated events with \texttt{SHERPA} include Multi-boson processes as well as the associate production of vector bosons and jets.  

% \paragraph{Powheg} 
% The \texttt{POWHEG} \cite{Powheg} framework is a matrix element generator at next-to-leading perturbative order.  The matrix element generation is interfaced with generators like \texttt{PYTHIA} or \texttt{HERWIG++} in order to simulate the parton shower.  This kind of combination of matrix element generator and parton shower simulation is used or top-related processes such as top-antitop pair production. 

% \paragraph{MadGraph5\_ aMC@NLO} \texttt{MadGraph5} \cite{Madgraph} is used as a matrix element calculator at next-to-leading perturbative order.  Similar to \texttt{POWHEG},  it is interfaced with \texttt{PYTHIA} or \texttt{HERWIG} to include parton showering. 

% \paragraph{Pythia}
% A second general purpose event generator used in this thesis is \texttt{PYTHIA 8}\cite{pythia},  even with matrix element calculation and parton showering possible within \texttt{PYTHIA}, it is widely used for its parton showering,  interfaced with \texttt{POWHEG} or \texttt{HERWIG}.  Additionally,  \texttt{PYTHIA} is used in this thesis to simulate minimum-bias proton-proton collisions.

% \paragraph{Herwig} The \texttt{HERWIG} \cite{Herwig,Herwig++} Monte Carlo event generator has capabilities to be used to simulate the matrix element,  but is only used within this thesis as a variation of the \texttt{PYTHIA} parton showering. 

% \paragraph{EvtGen}
% \texttt{EvtGen} \cite{EvtGen} is a framework that simulates the decay of final state particles.  Events associated with the production and decay of a top quark used in this thesis are simulated through a combination of \texttt{POWHEG}, \texttt{PYTHIA} and \texttt{EvtGen}.  Within this thesis, all events generated with a parton showering by \texttt{PYTHIA} include final state particle decays simulated with \texttt{EvtGen}.

% \subsection{ATLAS detector simulation}
% \label{sec:DAQ:AF2}


% To directly compare the data collected with the ATLAS detector with the prediction of \ac{SM} and \ac{BSM} events in simulation,  the interaction of the produced particles with the detector material has to be simulated.
% The Geant4 \cite{Geant4} software package is used to simulate the interaction of particles with the detector material.
% A full Geant4 model of the ATLAS detector is used to simulate the transition of particles produced in proton-proton collisions through the different detector layers. 

% The simulation of a large number of interactions necessary to mimick the ATLAS reconstruction is computationally extensive.  Especially the simulation of shower developments in the calorimeters consumes a large amount of CPU and computing time. 
% For many \ac{BSM} searches,  a large number of parameters affecting the predicted particle masses and interactions have to be simulated.  A 'fast' parameterised detector simulation has been developed to cope with this high simulation demand.  A so-called Atlfast-II or AFII setup simulation chain uses Geant4 simulation for the interactions in the \ac{ID} and muon spectrometer,  but a parametrised simulation called FastCaloSim for the particle interactions in the electromagnetic and hadronic calorimeter. 
% The improvements in computing time compared to Geant4 simulation of the full detector as well as a fast,  simplified Geant4 simulation is shown in Figure \ref{fig:DAQ:AFIIvsG4}.  The overall processing time is reduces by roughly an order of magnitude compared to the full Geant4 simulation \cite{AFIIprinciple}. 
% \begin{figure}[h]
% \centering
% \includegraphics[width=0.8\linewidth]{figures/DAQ/AFII_CPU_improvement.png}
% \caption{CPU time distributions for 250 $ \ttbar $ events compared for G4,  fast G4 and AFII setup,  taken from \cite{AFIIprinciple} \label{fig:DAQ:AFIIvsG4}}
% \end{figure}
% The fast calorimeter simulation FastCaloSim uses a parametrisation of the calorimeter response.  The parametrisation has been extracted through Geant4 simulation and tunes to data. 
% The main three simplifications include simplifying the detector geometry,  approximating the calorimeter cells as cuboids,  only reproducing the average lateral energy distributions and restricting the simulation to three types of initial particles. 

